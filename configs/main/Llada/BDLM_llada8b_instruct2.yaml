model_configuration:
  model_name: GSAI-ML/LLaDA-8B-Instruct
  tokenizer_name: GSAI-ML/LLaDA-8B-Instruct
  torch_dtype: bfloat16
  device_map: cuda:1
  trust_remote_code: true
  steps: 300
  gen_length: 300
  temperature: 0.5
  remasking: low_confidence
  model_specific_arguments:
    cfg_scale: 0.0
    mask_id: 126336
    block_length: 25

watermark_type: BDLM
watermark_config:
  delta: 2.0
  gamma: 0.5
  offset: 25
  context_len: 25
  topk: 40

evaluation_config:
  num_samples: 200
  batch_size: 1
  evaluation_datasets:
    - path: data/WaterBench/2-2_finance_qa.jsonl
      user_prompt: "You are a helpful assistant, please answer the following question with financial knowledge within 300 words:\n{context}\n{input}"
      chat: true
      max_length: 150
      min_length: 1
    - path: data/WaterBench/5-1_alpacafarm.jsonl
      user_prompt: "You are a helpful assistant, please answer the following instruction: \n{context}\n{input}"
      chat: true
      max_length: 150
      min_length: 1
  tqdm: true
