model_configuration:
  model_name: GSAI-ML/LLaDA-8B-Instruct
  tokenizer_name: GSAI-ML/LLaDA-8B-Instruct
  torch_dtype: bfloat16
  device_map: cuda
  trust_remote_code: true
  steps: 300
  gen_length: 300
  temperature: 0.5
  remasking: random
  model_specific_arguments:
    block_length: 25
    cfg_scale: 0.0
    mask_id: 126336
    
watermark_type: Unigram
watermark_config:
  delta: 2.0
  gamma: 0.25
  seed: 42
  
  
evaluation_config:
  num_samples: 200
  batch_size: 1
  evaluation_datasets:
    - path: data/WaterBench/2-1_longform_qa.jsonl
      user_prompt: "You are a helpful assistant, please answer the following question within 300 words:\n{context}\n{input}"
      chat: true
      max_length: 150
      min_length: 1
    - path: data/WaterBench/2-2_finance_qa.jsonl
      user_prompt: "You are a helpful assistant, please answer the following question with financial knowledge within 300 words:\n{context}\n{input}"
      chat: true
      max_length: 150
      min_length: 1
    - path: data/WaterBench/5-1_alpacafarm.jsonl
      user_prompt: "You are a helpful assistant, please answer the following instruction: \n{context}\n{input}"
      chat: true
      max_length: 150
      min_length: 1
  tqdm: true
